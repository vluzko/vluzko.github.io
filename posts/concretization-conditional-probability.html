<html lang="en">
 <head>
  <title>
   Concretization: Conditonal Expectation
  </title>
  <!-- Load mathjax -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js" type="text/javascript">
   MathJax.Hub.Config({
                extensions: ["tex2jax.js"],
                jax: ["input/TeX", "output/HTML-CSS"],
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                },
                "HTML-CSS": { availableFonts: ["TeX"] }
            });
  </script>
  <style>
   body {
                font-family: Dejavu Sans, Arial, Verdana, Helvetica, sans-serif;
            }

            #header {
                border-bottom: 1px solid black;
                display: flex;
                flex-direction: row;
            }

            #pfp {
                width: 80px;
                height: 80px;
            }

            .navbar ul {
                display: flex;
                list-style: none;
                position: relative;
                padding: 0;
                margin: 0;
                flex-direction: row;
                width: 100%;
                height: 100%;
            }

            .navbar li {
                display: flex;
                flex-direction: column;
                height: 100%;
                margin-left: 6px;
                margin-right: 6px;
                border: none;
                color: rgb(90, 90, 90);
            }

            .navbar a:hover {
                color: rgb(80, 80, 80);
                text-decoration: underline;
                /* background-color: darkgrey; */
            }

            .navbar a, a:visited{
                margin: auto;
                text-decoration: none;
                color: inherit;
            }

            #main {
                display: flex;
                flex-direction: row;
            }

            #sidebar {
                width: 100px;
            }

            #sidebar ul {
                list-style: none;
                color: rgb(90, 90, 90)
            }

            .content h2, h3, h4, h5 {
                color: rgb(90, 90, 90)
            }

            .content p {
                text-align: justify;
            }

            #content0 {
                margin-right: 100px;
                margin-left: 50px;
                max-width: 80%;
            }

            #blog-index {
                list-style: none;
            }

            #blog-index li {
                margin: 1px;
            }

            #post-index {
                list-style: none;
            }

            #post-index li {
                margin: 1px;
            }
  </style>
  <meta charset="utf-8"/>
 </head>
 <body>
  <div id="header">
   <img id="pfp" src="/assets/stokes-cartan.png"/>
   <nav class="navbar" id="navigation">
    <ul>
     <li>
      <a href="/index.html">
       Home
      </a>
     </li>
     <li>
      <a href="/blog.html">
       Blog
      </a>
     </li>
     <li>
      <a href="/about.html">
       About
      </a>
     </li>
    </ul>
   </nav>
  </div>
  <div id="main">
   <div class="sidebar" id="sidebar">
    <ul>
     <li>
      <a href="https://github.com/vluzko/">
       Github
      </a>
     </li>
     <li>
      <a href="https://www.linkedin.com/in/vincent-luczkow-843aa9b6/">
       LinkedIn
      </a>
     </li>
    </ul>
   </div>
   <div class="content" id="content0">
    <h2>
     Concretization: Conditional Probability and Expectation
     <a name="concretization:-conditional-probability-and-expectation">
     </a>
    </h2>
    <ul id="post-index">
     <li>
      <a href="#concretization:-conditional-probability-and-expectation">
       Concretization: Conditional Probability and Expectation
      </a>
     </li>
     <li>
      <a href="#general-conditional-expectation">
       General Conditional Expectation
      </a>
     </li>
     <li>
      <a href="#conditional-probability-on-a-$\sigma$---field">
       Conditional probability on a $\sigma$ - field
      </a>
     </li>
     <li>
      <a href="#conditioning-on-an-event">
       Conditioning on an event
      </a>
     </li>
     <li>
      <a href="#probability-conditional-on-an-event">
       Probability conditional on an event
      </a>
     </li>
    </ul>
    <p>
     Background required: basic measure theory and probability theory ($\sigma$-fields, measurable sets and functions, probability measures, random variables).
    </p>
    <p>
     In modern probability theory, we don't define conditional probability with the usual formula:
$$
P(A | B) = \frac{P(A \cap B)}{P(B)}
$$
    </p>
    <p>
     Instead we use a much more abstract formulation where we condition on an entire $\sigma$-field. This is much more general but also very far from the basic definition, and it's really quite hard to find a good exposition of how we recover usual conditional probability from this abstraction.
    </p>
    <h3>
     General Conditional Expectation
     <a name="general-conditional-expectation">
     </a>
    </h3>
    <p>
     "Normally" the conditional expectation of a random variable $X$ on a random variable $Y$ is defined as:
$$
E[X | Y=y] = \int_{-\infty}^{\infty} x P(X=x | Y=y) dx
$$
or for discrete random variables as:
$$
E[X | Y=y] = \sum_x x P(X=x | Y=y)
$$
This is nice and intuitive: we just take the formula for expectation and change the probability to a conditional probability.
    </p>
    <p>
     <em>
      General
     </em>
     conditional expectation is not nearly so nice. We don't even construct it: we use the
     <a href="https://en.wikipedia.org/wiki/Radon%E2%80%93Nikodym_theorem">
      Radon-Nikodym theorem
     </a>
     to prove that a random variable with a certain property must exist and be unique.
    </p>
    <p>
     We define the conditional expectation of a random variable $X$ on a $\sigma$-field $\mathcal{G}$ as a random variable $E[X | \mathcal{G}]$ that satisfies:
$$
    \int_G E[X | \mathcal{G}] dP = \int_G X dP
$$
for all $\mathcal{G}$ measurable sets $G$. We also require that $E[X | \mathcal{G}]$ be $\mathcal{G}$-measurable.
    </p>
    <p>
     First, not that $E[X | \mathcal{G}]$
     <em>
      isn't
     </em>
     being defined as an expectation operator being applied to the random variable $X$. $E[X | \mathcal{G}]$ defines a
     <em>
      single
     </em>
     random variable, it's just a weird variable name (obviously this variable name was picked to be consistent with the usual notion of conditional expectation).
    </p>
    <p>
     What does this definition actually mean? Suppose we're flipping a coin twice, and $X$ is the sum of the flips (heads is 1 and tails is 0). We want to condition $X$ on the first flip. With out new definition, we need to build a $\sigma$-field that only "sees" the first flip, i.e. one that cannot distinguish between the events $TH$ and $TT$ (and $HH$ and $HT$). If we think in terms of conditioning on a random variable, the groups would be "all events that have the same value for the random variable we're conditioning on". So we define $\mathcal{G}$ as:
$$
    \mathcal{G} := {\emptyset, {TH, TT}, {HH, HT}, \Omega}
$$
    </p>
    <p>
     Note that $X$
     <em>
      isn't
     </em>
     $\mathcal{G}$-measurable. The pre-image of $0$ under $X$ is $TT$: that's not a measurable set in $\mathcal{G}$. That's why we require $E[X | \mathcal{G}]$ to be $\mathcal{G}$-measurable: we construct $\mathcal{G}$ in a constrained way, grouping all the events that are the same under the condition together. Our original variable won't be measurable against these because it sees the individual events, not the groups, so we have to make a new variable that only sees the groups.
    </p>
    <p>
     The integral condition looks weird, but really it's just demanding that our conditional expectations satisfy the law of total expectation.
    </p>
    <h3>
     Conditional probability on a $\sigma$ - field
     <a name="conditional-probability-on-a-$\sigma$---field">
     </a>
    </h3>
    <p>
     Getting conditional probability out of this definition is very easy: the conditional probability of an event $A$ on a $\sigma$-field $\mathcal{G}$ is the conditional expectation of its indicator variable:
$$
P(A | \mathcal{G}) := E[I_A | \mathcal{G}]
$$
where $I_A$ is the indicator.
    </p>
    <p>
     Returning to our coin flip example, suppose we want to compute the probability the second flip is heads conditional on the first flip.
    </p>
    <p>
     Let's actually compute the integrals:
$$
\begin{align}
    \int_{{TH, TT}} E[I_A | \mathcal{G}] dP &amp;= \int_{{TH, TT}} I_A dP \\
    &amp;= I_A(TT) * 0.25 + I_A(TH) * 0.25 \\
    &amp;= 0.25
\end{align}
$$
and of course
$$
    \int_{{TH, TT}} E[I_A | \mathcal{G}] dP = E[I_A | \mathcal{G}] (TT)P(TT) + E[I_A | \mathcal{G}] (TH)P(TH)
$$
We know that $E[I_A | \mathcal{G}] (TH) = E[I_A | \mathcal{G}] (TT)$ (since it's $\mathcal{G}$-measurable). Define their value as $x$. So we have:
$$
\begin{align}
    x P(TT) + x P(TH) &amp;= \int_{{TH, TT}} E[I_A | \mathcal{G}] dP\\
    0.25x + 0.25x &amp;= 0.25\\
    \Rightarrow x &amp;= 0.5
\end{align}
$$
which is the answer we expect (of course a similar calculation applies to $HH$ and $HT$)
    </p>
    <h3>
     Conditioning on an event
     <a name="conditioning-on-an-event">
     </a>
    </h3>
    <p>
     Now we want to condition on a single event $B$. To do this, we condition on the $\sigma$-field generated by the event, i.e. the $\sigma$-field generated by ${B, B^C}$. Now let $\omega$ be any element of $B$. Then the conditional expectation of a $X$ on $B$ is $E[X | \sigma({B, B^C})]$ evaluated at $\omega$.
    </p>
    <h3>
     Probability conditional on an event
     <a name="probability-conditional-on-an-event">
     </a>
    </h3>
    <p>
     Finally we arrive at the familiar $P(A | B)$. By our previous definitions, this is:
$$
P(A | B) = E[I_A | \sigma({B, B^C})] (\omega)
$$
for some $\omega \in B$.
    </p>
    <p>
     Let's derive the familiar $P(A | B) = P(A \cap B) / P(B)$ formula from this.
    </p>
    <p>
     Suppose we're working entirely with discrete probabilities. Because $E[I_A | \sigma({B, B^C})$ is measurable against $E[I_A | \sigma({B, B^C})$, it must be constant on $B$. Call this value $c$. Since it's constant, we know that the integral over $B$ is just the constant times the probability of $B$:
$$
    \int_B E[I_A | \sigma({B, B^C}) dP = c \int_B dP = c P(B)
$$
We also know that $\int_B E[I_A | \sigma({B, B^C}) dP = \int_B I_A dP$, by the definition of conditional expectation. But the right hand side is simply $P(A \cap B)$, so we have:
$$
    \begin{align}
    c P(B) &amp;= P(A \cap B) \\
    c &amp;= \frac{P(A \cap B)}{P(B)}\\
    E[I_A | \sigma({B, B^C})] &amp;= \frac{P(A \cap B)}{P(B)}\\
    P(A | B) &amp;= \frac{P(A \cap B)}{P(B)}
    \end{align}
$$
    </p>
   </div>
  </div>
 </body>
</html>